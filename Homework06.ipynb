{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework06\n",
    "\n",
    "Some exercises with image and audio data preparation.\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Even more practice with lists\n",
    "- Get familiar with pandas `DataFrames`\n",
    "- Practice dataset exploration and normalization/scaling\n",
    "- Set up a dataset for proper classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025F-A/5020-utils/raw/main/src/audio_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025F-A/5020-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025F-A/5020-utils/raw/main/src/image_utils.py\n",
    "\n",
    "!wget -q https://github.com/PSAM-5020-2025F-A/Homework04/raw/main/Homework04_utils.pyc\n",
    "!wget -q https://github.com/PSAM-5020-2025F-A/Homework05/raw/main/Homework05_utils.pyc\n",
    "\n",
    "!wget -qO- https://github.com/PSAM-5020-2025F-A/5020-utils/releases/latest/download/forest-tree.tar.gz | tar xz\n",
    "!wget -qO- https://github.com/PSAM-5020-2025F-A/5020-utils/releases/latest/download/instruments.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from image_utils import make_image, get_pixels\n",
    "\n",
    "from Homework06_utils import AwesomeAudioClassifier, AwesomeImageClassifier\n",
    "\n",
    "AUDIO_PATH = \"./data/audio/instruments/test\"\n",
    "IMAGE_PATH = \"./data/image/forest-tree/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Image/Audio Classification\n",
    "\n",
    "We're going to re-visit the classification exercises from `Homework04` and `Homework05`.\n",
    "\n",
    "This exercise is a bit different though. In some ways it's the opposite of the previous exercises because we'll already have classification models ready to be used, but will have to normalize and standardize our dataset in order to run them. This is more representative of the type of work that goes into using real, pre-trained, ML models in the wild."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Models\n",
    "\n",
    "We have two `Awesome` models, one for audio classification (`AwesomeAudioClassifier`), and one for image classification (`AwesomeImageClassifier`).\n",
    "\n",
    "Unlike the classification models we set up for `Homework04` and `Homework05`, these models have more strict requirements about the shape and values of their input data. We can't run them on the files as they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "Audio and Image files are in the `data/audio/` and `data/image/` directories respectively.\n",
    "\n",
    "We will use the `get_training_data()` from each of our classifiers to get the initial training data and labels for our audio and image files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Features\n",
    "\n",
    "This is the challenging part.\n",
    "\n",
    "The data returned by `get_training_data()` is a representation of the content of the audio and image files, but it hasn't been processed or normalized in order to be used by the classifier models provided.\n",
    "\n",
    "We can try to create a `DataFrame` directly from those, and it might seem like it works, but if we take a look at the result we'll see some `NaN` (Not-a-Number) values in some of the columns, and if we send that to the model it will barf and complain about having `NaN`s in the data.\n",
    "\n",
    "This happens because all of the audios and images have different sizes. Hoooray !!\n",
    "\n",
    "Welcome to Machine Learning. This is probably where most of the time in any ML project is spent: cleaning up data and making sure it has the right format, size and shape that a model expects.\n",
    "\n",
    "For this exercise it won't be too hard to fix these.\n",
    "\n",
    "Let's start with the audio files since they're one-dimensional, and once we have the audio modeling working we'll come back to the image files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#040; padding:10px; width:calc(100% - 28px)\">\n",
    "\n",
    "## Audio Data\n",
    "\n",
    "Let's run `AwesomeAudioClassifier.get_training_data()` function to get some audio data. This function returns audio data and labels from files inside a specified directory.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = AwesomeAudioClassifier.get_training_data(AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Features\n",
    "\n",
    "The audio data returned is actually in the frequency domain and is not samples, so even though we can't play these audio files, we can still plot this data and will have to normalize and clean it before we can run it through our classifier.\n",
    "\n",
    "Let's take a look at this data.\n",
    "\n",
    "What are the labels ? How many records do we have ? How many features do we have in each record ? Can we plot our data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: How many records ?\n",
    "\n",
    "# TODO: How many features ?\n",
    "\n",
    "# TODO: Plot some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like data !\n",
    "\n",
    "Looks like audio frequency-domain data to be more specific.\n",
    "\n",
    "If we were to follow some of the data exploration steps we saw in class we would want to put this data in a `DataFrame` in order to get calculate some of its statistical properties, and maybe scale/normalize it before we use it in a classifier model.\n",
    "\n",
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(features)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it works, but when we look closely at the `DataFrame`, specially if we look at the features that are further to the right, we'll see our problem: `NaN` values.\n",
    "\n",
    "As previously mentioned, this happens because the length of our features is different for each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Audio Data\n",
    "\n",
    "Let's fix this by making all of the feature lists have the same length. We can either pad the short ones or slice the longer ones to have the same length as the shortest feature list. The second option is preferable since padding would require adding information to the dataset and that might have side effects.\n",
    "\n",
    "So, we'll go through the lists of lists, create a list of lengths and find the smallest length.\n",
    "\n",
    "Then, we'll iterate through the lists of lists and slice all the feature lists to have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: go through the list of features and make their lengths consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` created using the cropped features should look more consistent now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(cropped_features)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Empty features\n",
    "\n",
    "We've removed the `NaN` values, but it seems like we have a lot of columns that are all zeros or nearly all zeros.\n",
    "\n",
    "While it's not necessary, we could also remove these in order to speed up the modeling later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# sum of all columns\n",
    "display(features_df.sum())\n",
    "\n",
    "# columns where the sum is less than 100\n",
    "display((features_df.sum(axis=0) < 100))\n",
    "\n",
    "# TODO: remove columns with no information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model\n",
    "\n",
    "Now that we have a `DataFrame` with consistent rows, we can fit and evaluate our model.\n",
    "\n",
    "The next cell runs the pre-defined classification model, fitting it with our `features_df` `DataFrame` and then reports the accuracy of our model.\n",
    "\n",
    "We just have to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier and report training accuracy\n",
    "AwesomeAudioClassifier.fit(features_df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale / Normalize\n",
    "\n",
    "Hmmm.... it runs, but we can do better.\n",
    "\n",
    "We saw in class that normalizing/rescaling our features can help us find actual patterns in our data. It also helps models find patterns.\n",
    "\n",
    "Try scaling the `DataFrame` using either a `MinMaxScaler` or a `StandardScaler` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: scale/normalize features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model Again\n",
    "\n",
    "This time with scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier and report training accuracy\n",
    "AwesomeAudioClassifier.fit(features_scaled_df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Do different scaling strategies influence the prediction results ? What might that tell us about our data ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">\n",
    "EDIT THIS CELL WITH ANSWER\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#040; padding:10px; width:calc(100% - 28px)\">\n",
    "\n",
    "## Image Data\n",
    "\n",
    "This is a bit trickier, but only because our classifier model for images is a bit pickier. Not only do we have to ensure that all of our records have the same number of features (images have the same number of pixels), we will also have to convert the pixels into grayscale pixels.\n",
    "\n",
    "Let's start by reading the data and looking at what we get.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = AwesomeImageClassifier.get_training_data(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data\n",
    "\n",
    "What did we get in the `imgs` variable ? How many records do we have ? How many features does each record/image have ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: look at the imgs and labels variables and get some information about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Image Features\n",
    "\n",
    "It seems like we have actual `PIL` image objects and their labels. \n",
    "\n",
    "This will work to our advantage because if we try to just create a `DataFrame` of the extracted pixels from these images we'll probably have a problem with missing feature values again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for img in imgs:\n",
    "  features.append(get_pixels(img))\n",
    "\n",
    "print(len(features), len(features[0]), len(features[11]))\n",
    "\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Images\n",
    "\n",
    "We could follow a similar approach to how we fixed the audio data, and just slice our pixel arrays to have the same length as the shortest pixel array, but that will distort our images. Try it out to see the result, but instead of taking pixels out from the end of the image, what we really have to do is change their dimensions so they all have the same `width` and `height` before we get their pixels.\n",
    "\n",
    "There are a couple of ways to achieve this:\n",
    "- Crop: use the `image.crop()` function to cut the images.\n",
    "- Resize: use `image.resize()` to stretch/squeeze the images into specific shapes.\n",
    "\n",
    "Documentation for [`crop()`](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.crop) and [`resize()`](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.resize).\n",
    "\n",
    "Take a look at a few images before picking a strategy and then take a look after to see what the chosen strategy does to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: look at characteristics/dimensions of the images\n",
    "\n",
    "# TODO: go through the images and make their dimensions consistent\n",
    "\n",
    "# TODO: look at some images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features\n",
    "\n",
    "Now that we have images with consistent dimensions, we can extract their pixels and convert them to grayscale, so we get a nice looking `DataFrame` to send to our classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: calculate grayscale pixel values\n",
    "\n",
    "# TODO: look at some images with make_image()\n",
    "\n",
    "# TODO: create DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Image Model\n",
    "\n",
    "Now that we have a `DataFrame` with consistent features, we can fit and evaluate our model.\n",
    "\n",
    "The next cell runs the pre-defined classification model, fitting it with our `features_df` `DataFrame` and then reports the accuracy of our model.\n",
    "\n",
    "We just have to run it (and wait a bit because it can take up to $20$ seconds for it to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier and report training accuracy\n",
    "AwesomeImageClassifier.fit(features_df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling / Normalizing\n",
    "\n",
    "Run the classifier model again, but this time using normalized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create scaler object, scale data and re-run classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Do different scaling strategies influence the prediction results ? What might that tell us about our data ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">\n",
    "EDIT THIS CELL WITH ANSWER\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
